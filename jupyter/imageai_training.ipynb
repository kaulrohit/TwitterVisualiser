{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageai.Prediction.Custom import ModelTraining\n",
    "\n",
    "model_trainer = ModelTraining()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainer.setModelTypeAsResNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainer.setDataDirectory(r\"../../test/crime_dataset/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 112, 112, 64) 9472        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 112, 112, 64) 256         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 112, 112, 64) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 55, 55, 64)   0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 55, 55, 64)   4160        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 55, 55, 64)   256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 55, 55, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 55, 55, 64)   36928       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 55, 55, 64)   256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 55, 55, 64)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 55, 55, 256)  16640       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 55, 55, 256)  16640       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 55, 55, 256)  1024        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 55, 55, 256)  1024        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 55, 55, 256)  0           batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 55, 55, 256)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 55, 55, 64)   16448       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 55, 55, 64)   256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 55, 55, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 55, 55, 64)   36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 55, 55, 64)   256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 55, 55, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 55, 55, 256)  16640       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 55, 55, 256)  1024        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 55, 55, 256)  0           batch_normalization_7[0][0]      \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 55, 55, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 55, 55, 64)   16448       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 55, 55, 64)   256         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 55, 55, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 55, 55, 64)   36928       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 55, 55, 64)   256         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 55, 55, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 55, 55, 256)  16640       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 55, 55, 256)  1024        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 55, 55, 256)  0           batch_normalization_10[0][0]     \n",
      "                                                                 activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 55, 55, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 28, 28, 128)  32896       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 28, 28, 128)  512         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 28, 28, 128)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 28, 28, 128)  147584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 28, 28, 128)  512         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 28, 28, 512)  66048       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 28, 28, 512)  131584      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 28, 28, 512)  2048        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 28, 28, 512)  2048        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 28, 28, 512)  0           batch_normalization_14[0][0]     \n",
      "                                                                 batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 512)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 28, 28, 128)  65664       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 28, 28, 128)  512         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 128)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 28, 28, 128)  147584      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 28, 28, 128)  512         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 28, 28, 512)  66048       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 28, 28, 512)  2048        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           batch_normalization_17[0][0]     \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 28, 28, 128)  65664       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 28, 28, 128)  512         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 128)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 28, 28, 128)  147584      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 28, 28, 128)  512         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 28, 28, 512)  66048       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 28, 28, 512)  2048        conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           batch_normalization_20[0][0]     \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 28, 28, 128)  65664       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 28, 28, 128)  512         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 128)  0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 28, 28, 128)  147584      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 28, 28, 128)  512         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 28, 28, 512)  66048       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 28, 28, 512)  2048        conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           batch_normalization_23[0][0]     \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 14, 14, 256)  131328      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 14, 14, 256)  1024        conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 14, 14, 256)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 14, 14, 256)  590080      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 14, 14, 256)  1024        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 14, 14, 1024) 263168      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 14, 14, 1024) 525312      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 14, 14, 1024) 4096        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 14, 14, 1024) 4096        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 14, 14, 1024) 0           batch_normalization_27[0][0]     \n",
      "                                                                 batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 1024) 0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 14, 14, 256)  262400      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 14, 14, 256)  1024        conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 256)  0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 14, 14, 256)  590080      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 14, 14, 256)  1024        conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 14, 14, 1024) 263168      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 14, 14, 1024) 4096        conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           batch_normalization_30[0][0]     \n",
      "                                                                 activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 14, 14, 256)  262400      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 14, 14, 256)  1024        conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 256)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 14, 14, 256)  590080      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 14, 14, 256)  1024        conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 14, 14, 1024) 263168      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 14, 14, 1024) 4096        conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           batch_normalization_33[0][0]     \n",
      "                                                                 activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 14, 14, 256)  262400      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 14, 14, 256)  1024        conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 256)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 14, 14, 256)  590080      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 14, 14, 256)  1024        conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 14, 14, 1024) 263168      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 14, 14, 1024) 4096        conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_36[0][0]     \n",
      "                                                                 activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 14, 14, 256)  262400      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 14, 14, 256)  1024        conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 256)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 14, 14, 256)  590080      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 14, 14, 256)  1024        conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 14, 14, 1024) 263168      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 14, 14, 1024) 4096        conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_39[0][0]     \n",
      "                                                                 activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 14, 14, 256)  262400      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 14, 14, 256)  1024        conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 256)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 14, 14, 256)  590080      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 14, 14, 256)  1024        conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 14, 14, 1024) 263168      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 14, 14, 1024) 4096        conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_42[0][0]     \n",
      "                                                                 activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 7, 7, 512)    524800      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 7, 7, 512)    2048        conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 7, 7, 512)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 7, 7, 512)    2359808     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 7, 7, 512)    2048        conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 7, 7, 2048)   1050624     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 7, 7, 2048)   2099200     activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 7, 7, 2048)   8192        conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 7, 7, 2048)   8192        conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_46[0][0]     \n",
      "                                                                 batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 2048)   0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 7, 7, 512)    1049088     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 7, 7, 512)    2048        conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 512)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 7, 7, 512)    2359808     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 7, 7, 512)    2048        conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 7, 7, 2048)   1050624     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 7, 7, 2048)   8192        conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_49[0][0]     \n",
      "                                                                 activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 7, 7, 512)    1049088     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 7, 7, 512)    2048        conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 512)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 7, 7, 512)    2359808     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 7, 7, 512)    2048        conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 7, 7, 2048)   1050624     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 7, 7, 2048)   8192        conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_52[0][0]     \n",
      "                                                                 activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_avg_pooling (GlobalAvera (None, 2048)         0           activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 3)            6147        global_avg_pooling[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 3)            0           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 23,593,859\n",
      "Trainable params: 23,540,739\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n",
      "Using Enhanced Data Generation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1972 images belonging to 3 classes.\n",
      "Found 847 images belonging to 3 classes.\n",
      "JSON Mapping for the model classes saved to  /fred/oz126/rkaul/test/crime_dataset/json/model_class.json\n",
      "Number of experiments (Epochs) :  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rkaul/.local/lib/python3.6/site-packages/PIL/Image.py:953: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
      "  'to RGBA images')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 1.4615 - acc: 0.6204\n",
      "Epoch 00001: val_acc improved from -inf to 0.66827, saving model to /fred/oz126/rkaul/test/crime_dataset/models/model_ex-001_acc-0.668269.h5\n",
      "123/123 [==============================] - 169s 1s/step - loss: 1.4608 - acc: 0.6209 - val_loss: 4.5450 - val_acc: 0.6683\n",
      "Epoch 2/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 1.2115 - acc: 0.6255\n",
      "Epoch 00002: val_acc did not improve from 0.66827\n",
      "123/123 [==============================] - 74s 599ms/step - loss: 1.2165 - acc: 0.6235 - val_loss: 7.7327 - val_acc: 0.2909\n",
      "Epoch 3/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.9517 - acc: 0.6465\n",
      "Epoch 00003: val_acc did not improve from 0.66827\n",
      "123/123 [==============================] - 70s 570ms/step - loss: 0.9511 - acc: 0.6468 - val_loss: 0.9586 - val_acc: 0.6683\n",
      "Epoch 4/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.9230 - acc: 0.6460\n",
      "Epoch 00004: val_acc did not improve from 0.66827\n",
      "123/123 [==============================] - 62s 508ms/step - loss: 0.9241 - acc: 0.6458 - val_loss: 7.0668 - val_acc: 0.2668\n",
      "Epoch 5/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 1.0079 - acc: 0.6532\n",
      "Epoch 00005: val_acc improved from 0.66827 to 0.66947, saving model to /fred/oz126/rkaul/test/crime_dataset/models/model_ex-005_acc-0.669471.h5\n",
      "123/123 [==============================] - 62s 508ms/step - loss: 1.0048 - acc: 0.6540 - val_loss: 0.8002 - val_acc: 0.6695\n",
      "Epoch 6/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.9230 - acc: 0.6552\n",
      "Epoch 00006: val_acc did not improve from 0.66947\n",
      "123/123 [==============================] - 62s 507ms/step - loss: 0.9223 - acc: 0.6560 - val_loss: 0.9512 - val_acc: 0.6683\n",
      "Epoch 7/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.8675 - acc: 0.6552\n",
      "Epoch 00007: val_acc did not improve from 0.66947\n",
      "123/123 [==============================] - 62s 507ms/step - loss: 0.8669 - acc: 0.6550 - val_loss: 1.0027 - val_acc: 0.6166\n",
      "Epoch 8/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.8617 - acc: 0.6583\n",
      "Epoch 00008: val_acc did not improve from 0.66947\n",
      "123/123 [==============================] - 62s 506ms/step - loss: 0.8629 - acc: 0.6575 - val_loss: 0.8215 - val_acc: 0.6599\n",
      "Epoch 9/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.8452 - acc: 0.6629\n",
      "Epoch 00009: val_acc did not improve from 0.66947\n",
      "123/123 [==============================] - 61s 498ms/step - loss: 0.8430 - acc: 0.6641 - val_loss: 0.7942 - val_acc: 0.6683\n",
      "Epoch 10/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.8344 - acc: 0.6542\n",
      "Epoch 00010: val_acc did not improve from 0.66947\n",
      "123/123 [==============================] - 61s 496ms/step - loss: 0.8350 - acc: 0.6535 - val_loss: 0.7958 - val_acc: 0.6683\n",
      "Epoch 11/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.8255 - acc: 0.6583\n",
      "Epoch 00011: val_acc did not improve from 0.66947\n",
      "123/123 [==============================] - 63s 510ms/step - loss: 0.8257 - acc: 0.6575 - val_loss: 0.8306 - val_acc: 0.6635\n",
      "Epoch 12/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.8345 - acc: 0.6511\n",
      "Epoch 00012: val_acc did not improve from 0.66947\n",
      "123/123 [==============================] - 61s 499ms/step - loss: 0.8337 - acc: 0.6520 - val_loss: 0.8675 - val_acc: 0.6683\n",
      "Epoch 13/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.8183 - acc: 0.6578\n",
      "Epoch 00013: val_acc did not improve from 0.66947\n",
      "123/123 [==============================] - 62s 501ms/step - loss: 0.8172 - acc: 0.6585 - val_loss: 0.7871 - val_acc: 0.6683\n",
      "Epoch 14/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.8052 - acc: 0.6706\n",
      "Epoch 00014: val_acc did not improve from 0.66947\n",
      "123/123 [==============================] - 62s 506ms/step - loss: 0.8047 - acc: 0.6707 - val_loss: 0.7788 - val_acc: 0.6683\n",
      "Epoch 15/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.8051 - acc: 0.6603\n",
      "Epoch 00015: val_acc did not improve from 0.66947\n",
      "123/123 [==============================] - 64s 522ms/step - loss: 0.8041 - acc: 0.6611 - val_loss: 0.7916 - val_acc: 0.6454\n",
      "Epoch 16/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.8435 - acc: 0.6496\n",
      "Epoch 00016: val_acc did not improve from 0.66947\n",
      "123/123 [==============================] - 61s 492ms/step - loss: 0.8430 - acc: 0.6504 - val_loss: 0.7755 - val_acc: 0.6683\n",
      "Epoch 17/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.8180 - acc: 0.6578\n",
      "Epoch 00017: val_acc did not improve from 0.66947\n",
      "123/123 [==============================] - 60s 484ms/step - loss: 0.8172 - acc: 0.6595 - val_loss: 0.8356 - val_acc: 0.6671\n",
      "Epoch 18/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.7902 - acc: 0.6752\n",
      "Epoch 00018: val_acc did not improve from 0.66947\n",
      "123/123 [==============================] - 59s 477ms/step - loss: 0.7916 - acc: 0.6743 - val_loss: 0.9395 - val_acc: 0.6454\n",
      "Epoch 19/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.8301 - acc: 0.6557\n",
      "Epoch 00019: val_acc did not improve from 0.66947\n",
      "123/123 [==============================] - 63s 510ms/step - loss: 0.8281 - acc: 0.6570 - val_loss: 0.8886 - val_acc: 0.6034\n",
      "Epoch 20/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.7929 - acc: 0.6670\n",
      "Epoch 00020: val_acc did not improve from 0.66947\n",
      "123/123 [==============================] - 62s 506ms/step - loss: 0.7920 - acc: 0.6672 - val_loss: 0.8772 - val_acc: 0.6010\n",
      "Epoch 21/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.7976 - acc: 0.6593\n",
      "Epoch 00021: val_acc did not improve from 0.66947\n",
      "123/123 [==============================] - 63s 513ms/step - loss: 0.7964 - acc: 0.6606 - val_loss: 0.7865 - val_acc: 0.6623\n",
      "Epoch 22/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.8142 - acc: 0.6624\n",
      "Epoch 00022: val_acc did not improve from 0.66947\n",
      "123/123 [==============================] - 62s 507ms/step - loss: 0.8137 - acc: 0.6631 - val_loss: 0.7599 - val_acc: 0.6659\n",
      "Epoch 23/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.8305 - acc: 0.6542\n",
      "Epoch 00023: val_acc did not improve from 0.66947\n",
      "123/123 [==============================] - 63s 511ms/step - loss: 0.8275 - acc: 0.6565 - val_loss: 0.9113 - val_acc: 0.6562\n",
      "Epoch 24/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.8088 - acc: 0.6562\n",
      "Epoch 00024: val_acc did not improve from 0.66947\n",
      "123/123 [==============================] - 60s 490ms/step - loss: 0.8092 - acc: 0.6560 - val_loss: 0.9089 - val_acc: 0.6683\n",
      "Epoch 25/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.7887 - acc: 0.6685\n",
      "Epoch 00025: val_acc did not improve from 0.66947\n",
      "123/123 [==============================] - 61s 492ms/step - loss: 0.7882 - acc: 0.6687 - val_loss: 0.9494 - val_acc: 0.6635\n",
      "Epoch 26/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.7865 - acc: 0.6614\n",
      "Epoch 00026: val_acc did not improve from 0.66947\n",
      "123/123 [==============================] - 60s 491ms/step - loss: 0.7846 - acc: 0.6626 - val_loss: 1.0069 - val_acc: 0.6022\n",
      "Epoch 27/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.8264 - acc: 0.6583\n",
      "Epoch 00027: val_acc did not improve from 0.66947\n",
      "123/123 [==============================] - 70s 569ms/step - loss: 0.8257 - acc: 0.6591 - val_loss: 1.1278 - val_acc: 0.5913\n",
      "Epoch 28/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.8213 - acc: 0.6532\n",
      "Epoch 00028: val_acc did not improve from 0.66947\n",
      "123/123 [==============================] - 61s 498ms/step - loss: 0.8192 - acc: 0.6540 - val_loss: 0.8865 - val_acc: 0.6623\n",
      "Epoch 29/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.8052 - acc: 0.6655\n",
      "Epoch 00029: val_acc did not improve from 0.66947\n",
      "123/123 [==============================] - 63s 512ms/step - loss: 0.8028 - acc: 0.6672 - val_loss: 0.9109 - val_acc: 0.6683\n",
      "Epoch 30/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.8116 - acc: 0.6655\n",
      "Epoch 00030: val_acc did not improve from 0.66947\n",
      "123/123 [==============================] - 63s 509ms/step - loss: 0.8116 - acc: 0.6651 - val_loss: 0.7755 - val_acc: 0.6587\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/123 [============================>.] - ETA: 0s - loss: 0.8097 - acc: 0.6660\n",
      "Epoch 00031: val_acc did not improve from 0.66947\n",
      "123/123 [==============================] - 61s 492ms/step - loss: 0.8090 - acc: 0.6661 - val_loss: 1.5696 - val_acc: 0.5733\n",
      "Epoch 32/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.7832 - acc: 0.6798\n",
      "Epoch 00032: val_acc improved from 0.66947 to 0.67067, saving model to /fred/oz126/rkaul/test/crime_dataset/models/model_ex-032_acc-0.670673.h5\n",
      "123/123 [==============================] - 61s 497ms/step - loss: 0.7843 - acc: 0.6789 - val_loss: 0.8542 - val_acc: 0.6707\n",
      "Epoch 33/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.7886 - acc: 0.6701\n",
      "Epoch 00033: val_acc did not improve from 0.67067\n",
      "123/123 [==============================] - 63s 509ms/step - loss: 0.7865 - acc: 0.6717 - val_loss: 0.7966 - val_acc: 0.6671\n",
      "Epoch 34/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.7807 - acc: 0.6655\n",
      "Epoch 00034: val_acc did not improve from 0.67067\n",
      "123/123 [==============================] - 59s 481ms/step - loss: 0.7794 - acc: 0.6662 - val_loss: 0.7940 - val_acc: 0.6683\n",
      "Epoch 35/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.7940 - acc: 0.6614\n",
      "Epoch 00035: val_acc did not improve from 0.67067\n",
      "123/123 [==============================] - 61s 492ms/step - loss: 0.7950 - acc: 0.6611 - val_loss: 1.1666 - val_acc: 0.6683\n",
      "Epoch 36/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.7727 - acc: 0.6721\n",
      "Epoch 00036: val_acc improved from 0.67067 to 0.67548, saving model to /fred/oz126/rkaul/test/crime_dataset/models/model_ex-036_acc-0.675481.h5\n",
      "123/123 [==============================] - 61s 493ms/step - loss: 0.7731 - acc: 0.6707 - val_loss: 0.8021 - val_acc: 0.6755\n",
      "Epoch 37/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.8134 - acc: 0.6603\n",
      "Epoch 00037: val_acc did not improve from 0.67548\n",
      "123/123 [==============================] - 63s 510ms/step - loss: 0.8147 - acc: 0.6596 - val_loss: 0.9020 - val_acc: 0.6683\n",
      "Epoch 38/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.7916 - acc: 0.6660\n",
      "Epoch 00038: val_acc did not improve from 0.67548\n",
      "123/123 [==============================] - 60s 492ms/step - loss: 0.7928 - acc: 0.6662 - val_loss: 0.9483 - val_acc: 0.6442\n",
      "Epoch 39/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.7871 - acc: 0.6670\n",
      "Epoch 00039: val_acc did not improve from 0.67548\n",
      "123/123 [==============================] - 63s 511ms/step - loss: 0.7868 - acc: 0.6672 - val_loss: 0.8553 - val_acc: 0.6647\n",
      "Epoch 40/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.7888 - acc: 0.6644\n",
      "Epoch 00040: val_acc did not improve from 0.67548\n",
      "123/123 [==============================] - 60s 486ms/step - loss: 0.7867 - acc: 0.6667 - val_loss: 1.2993 - val_acc: 0.6082\n",
      "Epoch 41/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.7915 - acc: 0.6552\n",
      "Epoch 00041: val_acc did not improve from 0.67548\n",
      "123/123 [==============================] - 61s 494ms/step - loss: 0.7904 - acc: 0.6555 - val_loss: 0.9703 - val_acc: 0.6695\n",
      "Epoch 42/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.7767 - acc: 0.6803\n",
      "Epoch 00042: val_acc did not improve from 0.67548\n",
      "123/123 [==============================] - 61s 496ms/step - loss: 0.7773 - acc: 0.6794 - val_loss: 0.7805 - val_acc: 0.6659\n",
      "Epoch 43/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.7367 - acc: 0.6844\n",
      "Epoch 00043: val_acc did not improve from 0.67548\n",
      "123/123 [==============================] - 67s 544ms/step - loss: 0.7359 - acc: 0.6849 - val_loss: 0.7587 - val_acc: 0.6683\n",
      "Epoch 44/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.7723 - acc: 0.6573\n",
      "Epoch 00044: val_acc did not improve from 0.67548\n",
      "123/123 [==============================] - 69s 559ms/step - loss: 0.7708 - acc: 0.6580 - val_loss: 0.7489 - val_acc: 0.6731\n",
      "Epoch 45/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.7339 - acc: 0.6793\n",
      "Epoch 00045: val_acc did not improve from 0.67548\n",
      "123/123 [==============================] - 63s 508ms/step - loss: 0.7343 - acc: 0.6788 - val_loss: 0.7501 - val_acc: 0.6695\n",
      "Epoch 46/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.7475 - acc: 0.6803\n",
      "Epoch 00046: val_acc did not improve from 0.67548\n",
      "123/123 [==============================] - 60s 489ms/step - loss: 0.7474 - acc: 0.6799 - val_loss: 0.7516 - val_acc: 0.6731\n",
      "Epoch 47/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.7672 - acc: 0.6603\n",
      "Epoch 00047: val_acc did not improve from 0.67548\n",
      "123/123 [==============================] - 60s 487ms/step - loss: 0.7660 - acc: 0.6611 - val_loss: 0.7435 - val_acc: 0.6707\n",
      "Epoch 48/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.7377 - acc: 0.6767\n",
      "Epoch 00048: val_acc did not improve from 0.67548\n",
      "123/123 [==============================] - 59s 477ms/step - loss: 0.7374 - acc: 0.6768 - val_loss: 0.7437 - val_acc: 0.6743\n",
      "Epoch 49/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.7436 - acc: 0.6747\n",
      "Epoch 00049: val_acc did not improve from 0.67548\n",
      "123/123 [==============================] - 59s 483ms/step - loss: 0.7434 - acc: 0.6753 - val_loss: 0.7465 - val_acc: 0.6659\n",
      "Epoch 50/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.7209 - acc: 0.6895\n",
      "Epoch 00050: val_acc did not improve from 0.67548\n",
      "123/123 [==============================] - 59s 479ms/step - loss: 0.7210 - acc: 0.6890 - val_loss: 0.7432 - val_acc: 0.6683\n",
      "Epoch 51/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.7368 - acc: 0.6757\n",
      "Epoch 00051: val_acc did not improve from 0.67548\n",
      "123/123 [==============================] - 59s 481ms/step - loss: 0.7374 - acc: 0.6758 - val_loss: 0.7645 - val_acc: 0.6647\n",
      "Epoch 52/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.7234 - acc: 0.6906\n",
      "Epoch 00052: val_acc did not improve from 0.67548\n",
      "123/123 [==============================] - 59s 481ms/step - loss: 0.7241 - acc: 0.6905 - val_loss: 0.7635 - val_acc: 0.6683\n",
      "Epoch 53/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.7365 - acc: 0.6793\n",
      "Epoch 00053: val_acc improved from 0.67548 to 0.67788, saving model to /fred/oz126/rkaul/test/crime_dataset/models/model_ex-053_acc-0.677885.h5\n",
      "123/123 [==============================] - 59s 479ms/step - loss: 0.7364 - acc: 0.6799 - val_loss: 0.7409 - val_acc: 0.6779\n",
      "Epoch 54/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.7278 - acc: 0.6798\n",
      "Epoch 00054: val_acc did not improve from 0.67788\n",
      "123/123 [==============================] - 58s 469ms/step - loss: 0.7260 - acc: 0.6809 - val_loss: 0.7421 - val_acc: 0.6743\n",
      "Epoch 55/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.7336 - acc: 0.6696\n",
      "Epoch 00055: val_acc did not improve from 0.67788\n",
      "123/123 [==============================] - 60s 488ms/step - loss: 0.7324 - acc: 0.6702 - val_loss: 0.7389 - val_acc: 0.6779\n",
      "Epoch 56/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.7336 - acc: 0.6839\n",
      "Epoch 00056: val_acc did not improve from 0.67788\n",
      "123/123 [==============================] - 59s 478ms/step - loss: 0.7345 - acc: 0.6844 - val_loss: 0.7432 - val_acc: 0.6767\n",
      "Epoch 57/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.6956 - acc: 0.6977\n",
      "Epoch 00057: val_acc did not improve from 0.67788\n",
      "123/123 [==============================] - 59s 477ms/step - loss: 0.6954 - acc: 0.6977 - val_loss: 0.7516 - val_acc: 0.6683\n",
      "Epoch 58/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.7294 - acc: 0.6829\n",
      "Epoch 00058: val_acc did not improve from 0.67788\n",
      "123/123 [==============================] - 59s 482ms/step - loss: 0.7274 - acc: 0.6839 - val_loss: 0.7397 - val_acc: 0.6743\n",
      "Epoch 59/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.7182 - acc: 0.6885\n",
      "Epoch 00059: val_acc did not improve from 0.67788\n",
      "123/123 [==============================] - 59s 483ms/step - loss: 0.7165 - acc: 0.6895 - val_loss: 0.7375 - val_acc: 0.6695\n",
      "Epoch 60/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.6996 - acc: 0.7003\n",
      "Epoch 00060: val_acc did not improve from 0.67788\n",
      "123/123 [==============================] - 58s 474ms/step - loss: 0.6994 - acc: 0.6997 - val_loss: 0.7576 - val_acc: 0.6743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.7109 - acc: 0.6834\n",
      "Epoch 00061: val_acc did not improve from 0.67788\n",
      "123/123 [==============================] - 58s 472ms/step - loss: 0.7131 - acc: 0.6819 - val_loss: 0.7660 - val_acc: 0.6659\n",
      "Epoch 62/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.7034 - acc: 0.6860\n",
      "Epoch 00062: val_acc did not improve from 0.67788\n",
      "123/123 [==============================] - 59s 477ms/step - loss: 0.7022 - acc: 0.6865 - val_loss: 0.7529 - val_acc: 0.6731\n",
      "Epoch 63/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.6909 - acc: 0.6875\n",
      "Epoch 00063: val_acc did not improve from 0.67788\n",
      "123/123 [==============================] - 62s 507ms/step - loss: 0.6919 - acc: 0.6865 - val_loss: 0.7466 - val_acc: 0.6707\n",
      "Epoch 64/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.7152 - acc: 0.6788\n",
      "Epoch 00064: val_acc did not improve from 0.67788\n",
      "123/123 [==============================] - 62s 501ms/step - loss: 0.7134 - acc: 0.6794 - val_loss: 0.7469 - val_acc: 0.6695\n",
      "Epoch 65/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.6765 - acc: 0.7075\n",
      "Epoch 00065: val_acc did not improve from 0.67788\n",
      "123/123 [==============================] - 58s 471ms/step - loss: 0.6752 - acc: 0.7073 - val_loss: 0.7434 - val_acc: 0.6779\n",
      "Epoch 66/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.7059 - acc: 0.6860\n",
      "Epoch 00066: val_acc did not improve from 0.67788\n",
      "123/123 [==============================] - 61s 498ms/step - loss: 0.7056 - acc: 0.6865 - val_loss: 0.7448 - val_acc: 0.6755\n",
      "Epoch 67/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.7085 - acc: 0.6880\n",
      "Epoch 00067: val_acc improved from 0.67788 to 0.68269, saving model to /fred/oz126/rkaul/test/crime_dataset/models/model_ex-067_acc-0.682692.h5\n",
      "123/123 [==============================] - 60s 492ms/step - loss: 0.7090 - acc: 0.6880 - val_loss: 0.7431 - val_acc: 0.6827\n",
      "Epoch 68/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.6827 - acc: 0.6983\n",
      "Epoch 00068: val_acc improved from 0.68269 to 0.68510, saving model to /fred/oz126/rkaul/test/crime_dataset/models/model_ex-068_acc-0.685096.h5\n",
      "123/123 [==============================] - 60s 492ms/step - loss: 0.6820 - acc: 0.6987 - val_loss: 0.7433 - val_acc: 0.6851\n",
      "Epoch 69/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.6958 - acc: 0.6865\n",
      "Epoch 00069: val_acc did not improve from 0.68510\n",
      "123/123 [==============================] - 58s 470ms/step - loss: 0.6983 - acc: 0.6840 - val_loss: 0.7419 - val_acc: 0.6791\n",
      "Epoch 70/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.6965 - acc: 0.6916\n",
      "Epoch 00070: val_acc did not improve from 0.68510\n",
      "123/123 [==============================] - 63s 512ms/step - loss: 0.6960 - acc: 0.6921 - val_loss: 0.7417 - val_acc: 0.6803\n",
      "Epoch 71/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.6967 - acc: 0.6885\n",
      "Epoch 00071: val_acc did not improve from 0.68510\n",
      "123/123 [==============================] - 59s 476ms/step - loss: 0.6962 - acc: 0.6890 - val_loss: 0.7409 - val_acc: 0.6839\n",
      "Epoch 72/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.6891 - acc: 0.6911\n",
      "Epoch 00072: val_acc did not improve from 0.68510\n",
      "123/123 [==============================] - 59s 478ms/step - loss: 0.6891 - acc: 0.6921 - val_loss: 0.7429 - val_acc: 0.6827\n",
      "Epoch 73/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.7022 - acc: 0.6931\n",
      "Epoch 00073: val_acc did not improve from 0.68510\n",
      "123/123 [==============================] - 57s 465ms/step - loss: 0.6995 - acc: 0.6956 - val_loss: 0.7438 - val_acc: 0.6839\n",
      "Epoch 74/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.6775 - acc: 0.7003\n",
      "Epoch 00074: val_acc did not improve from 0.68510\n",
      "123/123 [==============================] - 60s 485ms/step - loss: 0.6781 - acc: 0.6997 - val_loss: 0.7424 - val_acc: 0.6851\n",
      "Epoch 75/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.6933 - acc: 0.6814\n",
      "Epoch 00075: val_acc improved from 0.68510 to 0.68750, saving model to /fred/oz126/rkaul/test/crime_dataset/models/model_ex-075_acc-0.687500.h5\n",
      "123/123 [==============================] - 58s 471ms/step - loss: 0.6925 - acc: 0.6819 - val_loss: 0.7418 - val_acc: 0.6875\n",
      "Epoch 76/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.6919 - acc: 0.6962\n",
      "Epoch 00076: val_acc improved from 0.68750 to 0.68990, saving model to /fred/oz126/rkaul/test/crime_dataset/models/model_ex-076_acc-0.689904.h5\n",
      "123/123 [==============================] - 60s 486ms/step - loss: 0.6923 - acc: 0.6956 - val_loss: 0.7420 - val_acc: 0.6899\n",
      "Epoch 77/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.6761 - acc: 0.6988\n",
      "Epoch 00077: val_acc did not improve from 0.68990\n",
      "123/123 [==============================] - 58s 471ms/step - loss: 0.6758 - acc: 0.6987 - val_loss: 0.7429 - val_acc: 0.6899\n",
      "Epoch 78/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.6939 - acc: 0.6962\n",
      "Epoch 00078: val_acc did not improve from 0.68990\n",
      "123/123 [==============================] - 59s 479ms/step - loss: 0.6920 - acc: 0.6966 - val_loss: 0.7432 - val_acc: 0.6899\n",
      "Epoch 79/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.7124 - acc: 0.6803\n",
      "Epoch 00079: val_acc did not improve from 0.68990\n",
      "123/123 [==============================] - 58s 474ms/step - loss: 0.7099 - acc: 0.6814 - val_loss: 0.7439 - val_acc: 0.6875\n",
      "Epoch 80/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.6769 - acc: 0.6983\n",
      "Epoch 00080: val_acc did not improve from 0.68990\n",
      "123/123 [==============================] - 59s 477ms/step - loss: 0.6769 - acc: 0.6982 - val_loss: 0.7419 - val_acc: 0.6899\n",
      "Epoch 81/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.7043 - acc: 0.6839\n",
      "Epoch 00081: val_acc did not improve from 0.68990\n",
      "123/123 [==============================] - 59s 481ms/step - loss: 0.7030 - acc: 0.6845 - val_loss: 0.7421 - val_acc: 0.6863\n",
      "Epoch 82/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.6829 - acc: 0.7008\n",
      "Epoch 00082: val_acc did not improve from 0.68990\n",
      "123/123 [==============================] - 60s 489ms/step - loss: 0.6836 - acc: 0.6997 - val_loss: 0.7431 - val_acc: 0.6899\n",
      "Epoch 83/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.6906 - acc: 0.6962\n",
      "Epoch 00083: val_acc did not improve from 0.68990\n",
      "123/123 [==============================] - 61s 498ms/step - loss: 0.6890 - acc: 0.6967 - val_loss: 0.7436 - val_acc: 0.6887\n",
      "Epoch 84/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.6829 - acc: 0.7024\n",
      "Epoch 00084: val_acc did not improve from 0.68990\n",
      "123/123 [==============================] - 63s 516ms/step - loss: 0.6834 - acc: 0.7027 - val_loss: 0.7428 - val_acc: 0.6887\n",
      "Epoch 85/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.6900 - acc: 0.6972\n",
      "Epoch 00085: val_acc did not improve from 0.68990\n",
      "123/123 [==============================] - 65s 528ms/step - loss: 0.6900 - acc: 0.6982 - val_loss: 0.7427 - val_acc: 0.6899\n",
      "Epoch 86/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.6890 - acc: 0.6901\n",
      "Epoch 00086: val_acc improved from 0.68990 to 0.69351, saving model to /fred/oz126/rkaul/test/crime_dataset/models/model_ex-086_acc-0.693510.h5\n",
      "123/123 [==============================] - 63s 514ms/step - loss: 0.6880 - acc: 0.6911 - val_loss: 0.7446 - val_acc: 0.6935\n",
      "Epoch 87/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.6881 - acc: 0.6911\n",
      "Epoch 00087: val_acc did not improve from 0.69351\n",
      "123/123 [==============================] - 66s 533ms/step - loss: 0.6919 - acc: 0.6895 - val_loss: 0.7426 - val_acc: 0.6887\n",
      "Epoch 88/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.6749 - acc: 0.7018\n",
      "Epoch 00088: val_acc did not improve from 0.69351\n",
      "123/123 [==============================] - 65s 526ms/step - loss: 0.6738 - acc: 0.7017 - val_loss: 0.7415 - val_acc: 0.6911\n",
      "Epoch 89/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.6831 - acc: 0.7039\n",
      "Epoch 00089: val_acc did not improve from 0.69351\n",
      "123/123 [==============================] - 64s 522ms/step - loss: 0.6833 - acc: 0.7038 - val_loss: 0.7432 - val_acc: 0.6911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.6971 - acc: 0.6921\n",
      "Epoch 00090: val_acc did not improve from 0.69351\n",
      "123/123 [==============================] - 65s 531ms/step - loss: 0.6973 - acc: 0.6921 - val_loss: 0.7437 - val_acc: 0.6923\n",
      "Epoch 91/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.6810 - acc: 0.6962\n",
      "Epoch 00091: val_acc did not improve from 0.69351\n",
      "123/123 [==============================] - 64s 519ms/step - loss: 0.6856 - acc: 0.6941 - val_loss: 0.7442 - val_acc: 0.6887\n",
      "Epoch 92/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.6798 - acc: 0.6906\n",
      "Epoch 00092: val_acc did not improve from 0.69351\n",
      "123/123 [==============================] - 65s 532ms/step - loss: 0.6780 - acc: 0.6921 - val_loss: 0.7431 - val_acc: 0.6935\n",
      "Epoch 93/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.6974 - acc: 0.6942\n",
      "Epoch 00093: val_acc did not improve from 0.69351\n",
      "123/123 [==============================] - 64s 524ms/step - loss: 0.6967 - acc: 0.6946 - val_loss: 0.7437 - val_acc: 0.6923\n",
      "Epoch 94/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.6940 - acc: 0.6880\n",
      "Epoch 00094: val_acc did not improve from 0.69351\n",
      "123/123 [==============================] - 63s 515ms/step - loss: 0.6952 - acc: 0.6880 - val_loss: 0.7441 - val_acc: 0.6935\n",
      "Epoch 95/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.6835 - acc: 0.6957\n",
      "Epoch 00095: val_acc did not improve from 0.69351\n",
      "123/123 [==============================] - 61s 496ms/step - loss: 0.6843 - acc: 0.6956 - val_loss: 0.7426 - val_acc: 0.6923\n",
      "Epoch 96/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.6818 - acc: 0.6998\n",
      "Epoch 00096: val_acc did not improve from 0.69351\n",
      "123/123 [==============================] - 61s 497ms/step - loss: 0.6819 - acc: 0.6987 - val_loss: 0.7439 - val_acc: 0.6935\n",
      "Epoch 97/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.6856 - acc: 0.6921\n",
      "Epoch 00097: val_acc did not improve from 0.69351\n",
      "123/123 [==============================] - 61s 494ms/step - loss: 0.6847 - acc: 0.6931 - val_loss: 0.7439 - val_acc: 0.6923\n",
      "Epoch 98/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.6835 - acc: 0.6824\n",
      "Epoch 00098: val_acc did not improve from 0.69351\n",
      "123/123 [==============================] - 61s 494ms/step - loss: 0.6840 - acc: 0.6814 - val_loss: 0.7442 - val_acc: 0.6935\n",
      "Epoch 99/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.6929 - acc: 0.6972\n",
      "Epoch 00099: val_acc did not improve from 0.69351\n",
      "123/123 [==============================] - 60s 492ms/step - loss: 0.6923 - acc: 0.6967 - val_loss: 0.7433 - val_acc: 0.6923\n",
      "Epoch 100/100\n",
      "122/123 [============================>.] - ETA: 0s - loss: 0.6821 - acc: 0.6993\n",
      "Epoch 00100: val_acc did not improve from 0.69351\n",
      "123/123 [==============================] - 60s 488ms/step - loss: 0.6839 - acc: 0.6992 - val_loss: 0.7423 - val_acc: 0.6911\n"
     ]
    }
   ],
   "source": [
    "model_trainer.trainModel(num_objects=3, num_experiments=100, enhance_data=True, batch_size=16, show_network_summary=True,save_full_model=\"imageai_test.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageai.Prediction.Custom import CustomImagePrediction\n",
    "import os\n",
    "\n",
    "execution_path = 'crime_dataset'\n",
    "\n",
    "prediction = CustomImagePrediction()\n",
    "prediction.setModelTypeAsResNet()\n",
    "prediction.setModelPath(os.path.join(execution_path, \"models/model_ex-086_acc-0.693510.h5\"))\n",
    "prediction.setJsonPath(os.path.join(execution_path, \"json/model_class.json\"))\n",
    "prediction.loadModel(num_objects=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>363c6f069ce505caa7cc06219083b8fc9529153d147d3f...</td>\n",
       "      <td>HighCrime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ef766aa6822317852f35d7203bcc99b30f1757968a1e8f...</td>\n",
       "      <td>HighCrime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7aa9101d523bd79889d4feca003b67a1b6be45d000d12b...</td>\n",
       "      <td>NoCrime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e5fe1e87c217faf39e8023f37be3a15e774edb24451879...</td>\n",
       "      <td>HighCrime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71225e5300acdc6bf87b23a084413ba6aa912c6a749179...</td>\n",
       "      <td>NoCrime</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id       tags\n",
       "0  363c6f069ce505caa7cc06219083b8fc9529153d147d3f...  HighCrime\n",
       "1  ef766aa6822317852f35d7203bcc99b30f1757968a1e8f...  HighCrime\n",
       "2  7aa9101d523bd79889d4feca003b67a1b6be45d000d12b...    NoCrime\n",
       "3  e5fe1e87c217faf39e8023f37be3a15e774edb24451879...  HighCrime\n",
       "4  71225e5300acdc6bf87b23a084413ba6aa912c6a749179...    NoCrime"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('cleaned_trinary_test_30.csv')\n",
    "df = df.drop(columns='object_labels')\n",
    "image_ids = df['id']\n",
    "tags = df['tags']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for image,tag in zip(image_ids,tags):\n",
    "    predictions, probabilities = prediction.predictImage(os.path.join(\"images\", image), result_count=1)\n",
    "\n",
    "    for eachPrediction, eachProbability in zip(predictions, probabilities):\n",
    "        print(tag,eachPrediction , eachProbability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
